# 2021.08

## 8/2

### Amazon EC2 (Elastic computer cloud)

* 가상환경에 있는 서버 (클라우드)
* 하나의 서버를 instance라고 한다. 

### VPC (virtual private cloud)

* networking layer for EC2 
* VPC에서 사용하는 사설 IP 대역이 따로 존재한다.
* Subnet 이란 위의 IP주소를 나눈 것인데 보안을 위해 특정 IP주소는 인터넷과 쉽게 연결할 수 있게 해두고 특정 주소는 인터넷 연결이 되어 있지 않다. 
* Internate gateway는 인터넷 접속을 위한 gateway인데 public subnet에서만 연결 가능하다. 
* NAT gateway는 private subnet이 인터넷 접속을 해야할 경우 public subnet안에서 대신 연결해주는 gateway이다.
* VPC endpoint는 인터넷연결없이 aws안에 있는 데이터를 연결할 수 있는 서비스이다. 

<img src="https://i.loli.net/2021/08/02/UrZ71z2cOmW3qfo.png" alt="스크린샷 2021-08-02 오후 10.07.19" style="zoom:50%;" />

### 사설 IP vs 공인 IP

* 공인 IP는 ISP에서 제공하는 IP 주소이고 누구나 접근 가능하다
* 사설 IP는 개인 라우터를 통해 개인 pc에 할당되는 주소이다. 
* 개인 라우터는 공인 IP를 제공받아야 개인 pc들이 사설 IP를 사용해 인터넷에 접근할 수 있다. 

<img src="https://i.loli.net/2021/08/02/khFMA1vUNQrdDZb.png" alt="스크린샷 2021-08-02 오후 9.43.58" style="zoom:50%;" />

Reference 

* [VPC 개념 이해하기](https://jbhs7014.tistory.com/164#:~:text=%F0%9F%93%8C%20VPC%EC%9D%98%20%EA%B0%9C%EB%85%90,%ED%95%98%EB%8A%94%20%EA%B0%80%EC%83%81%EC%9D%98%20%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%EC%9D%B4%EB%8B%A4.&text=VPC%EB%A5%BC%20%EC%A0%81%EC%9A%A9%ED%95%98%EB%A9%B4%20%EC%95%84%EB%9E%98%EC%99%80,%EC%9D%84%20%EC%A0%81%EC%9A%A9%ED%95%A0%20%EC%88%98%20%EC%9E%88%EB%8B%A4.)
* https://velog.io/@hidaehyunlee/%EA%B3%B5%EC%9D%B8Public-%EC%82%AC%EC%84%A4Private-IP%EC%9D%98-%EC%B0%A8%EC%9D%B4%EC%A0%90



## 8/3

### Classes of IP address

* Class가 나눠져있는 이유? Network 와 host 의 갯수에 따라 IP 주소를 알맞게 구성하기 위해 만들어짐. 
* Class A->E까지 logarithmically decreasing IP address 갯수가 있다.
* 예) Class A 는 2^24 - 2 개의 host와 2^7 개의 network를 수용할 수 있다. 

<img src="https://i.loli.net/2021/08/03/yheZqcUKvGBs5p4.png" alt="스크린샷 2021-08-03 오후 8.19.27" style="zoom:50%;" />

(https://www.youtube.com/watch?v=vcArZIAmnYQ&list=RDCMUCr0Ze4SR3MHXAgz1TvRYL7Q&start_radio=1&rv=vcArZIAmnYQ&t=28)

### Subnet mask

* IP address에서 network 랑 host address를 구분할 수 있게 해주는 바이너리 마스크
* 예) 255.255.255.0

### CIDR (Classless Inter-Domain Routing, CIDR)

* classful IP address는 scalability 문제를 가지고 있다. 왜냐면 예를 들어, class C로는 host 갯수가 부족한데 B를 쓰기엔 너무 host 갯수가 많은 경우가 있으니 모자르거나 낭비가 심한 경우가 생긴다.  
* classless 방법을 사용하면 class를 나누지 않고 subnet mask를 이용해서 자유롭게 network prefix 랑 host identifier를 정할 수  있다. 

### CIDR notation 

* Subnet mask의 255.255 ...  어쩌고의 간소화 버전이다. 별거 아니고 바이너리 notation에서 1이 몇개 있느냐를 "/{1의 갯수}"로 나타내는 것이다. 
* 예) 255.255.255.0 는 1이 24개니까 "/24"



## 8/4 

###  Snowflake data warehouse 

* Table paritioning for efficient query handling - pruning 
* Caches data in compute nodes in order to reduce I/O latency between compute and storage nodes
* Compute = EC2, storage = S3 
* semi-structured data도 column에 저장 가능하고 join할수 있다 : VARIANT, ARRAY, OBJECT
* 하나의 virtual warehouse 에 여러 worker node (EC2) 들이 포함되는데 각 node 마다 cache 를 가지고 있다. 그런데 이 cache 는 node들 사이에서 공유되는데 그렇다면 cache miss를 최소화하기 위해서는 특정 데이터 파일을 읽을때마다 같은 cache에 저장되게 할 수 있다면 좋을 것이다. 그래서 consistent hashing을 사용해서 이를 어느정도 해결한다고 한다. 

모르는거 투성이~~ 아직도 뭔가 너무 추상적이야... 



## 8/5

### AWS intro

* AWS is basically a client-server model 
  * where server =  Amazon EC2 (virtual server)
* Cloud computing : on-demand delivery of IT resources over the internet  - 유저가 리소스가 필요할때마다 제공해주는 서비스 

### Random OS vocabs to study 

* BIOS
* RAID (Redundant Array of Inexpensive Disks) : data storage virtualization technology인데 여러 물리 디스크를 사용하지만 사실은 하나만 사용하는 것처럼  속이기 위해 data redundancy나 performance문제를 해결한다. 여러 단계들이 있다 (ex. RAID 0는 striping을 하는데 즉, 하나의 데이터를 여러 디스크에 쪼개서 둔다는 뜻.)
* Bootloader 
* cloud init은 AWS EC2를 만들기 위해 필요한 configuration을 관리해주는 툴이다
* elastic beanstalk 
* vmstat, iostat 
* uptime 
  * load average (현재 CPU 점유율)
* nproc : core 몇개
* echo $$ : 현재 process ID 
* initd vs systemd 
* cd /proc/17827/task

## 8/7

### Tail recursion in Scala

* Tail recursion 이라는건 마지막으로 시행하는 작업이 recursive function 이기만 할때를 뜻한다. 이 방법을 선호하는 이유는 stack에 이 마지막 함수 하나에 대해서만 스택을 저장해두면 되기 때문이다. 
* @tail.rec 이라는 데코레이터를 쓰면 스칼라에서 내 recursive function이 

## 8/8

### Higher order functions 

* "Functions are first-class values" 라고 하면 함수들도 다른 value들과 마찬가지로 다른 함수의 파라미터나 리턴값으로 지정할 수 있다는 이야기다
* 다른 함수를 자신의 파라미터로 받거나 리턴하는 함수를 보고 higher order function이라고 함. 

* 맨날 함수 이름 정하기 귀찮으니까 anonymous function 을 만들수 있는데 아래 두개는 같은 역할을 한다. 

  ```
  def cube(x: Int) : Int = x * x * x
  
  (x: Int) => x * x * x 
  ```

* higher order function을 많이 활용하게 되면 nested function들도 많이 생기고 smaller function들이 많이 생기는데, 이를 위해 스칼라에서는 간편히 작성할 수 있는 방식을 제공한다. 그게 currying 이다. 

  ```
  def sum(f: Int => Int) (a: Int, b: Int) : Int = ...
  ```

  sum이라는 함수는 다른 함수 f 를 받고 또 다른 함수를 리턴한다. 그 함수는 a, b 파라미터를 받고 int를 리턴함. 

개머리아프네 이게 뭐야.....파이썬 내놔... 



## 8/14

### Network 공부 

* 같은 네트워크에 있어야 통신 가능하고, 다른 네트워크와 통신하려면 router를 통해 간접적으로 연결해야한다. 
* 모든 피지컬 서버는 MAC (Media access control) 주소가 있어야하고 이 MAC 주소가 있어야 서버끼리 서로 통신을 할 수 있다.  
* ARP (Adress resolution protocol) 를 통해서 자기 네트워크안에 있는 기기들의 MAC주소를 알아낼 수 있다. 
  * 내 내트워크안에 특정 ip 주소를 가지고 있는 서버의 MAC주소를 알고 싶으면 네트워크 안에 있는 모든 서버들에게 물어본다. 그러면 주인공이 답변을 준다 ㅎㅎ (Who has xxxx. Tell xxxxx 이런식으로 메세지 보내는거다) 

자주 보이는 면접 질문 : www.google.com 을 브라우저 주소창에 치면 일어나는 작업들 다 설명하기 

1. 실제 ip 주소를 받아온다. DNS 캐시를 확인해보던지 직접 DNS서버에게 물어본다. 
2. DNS서버가 내 
3. TCP/IP 핸드쉐이크를 시도한다
4. 성공했다면 브라우저는 http request를 보낸다.  
5. 구글 서버는 http response를 보내준다. 
6. 브라우저는 html을 보여준다. 

## 8/19

### Kafka

Distributed log processing 을 할 수 있는 플랫폼이다. Push가 아니라 pull-based라서 원하는 유저가 원하는 데이터에만 subscribe하는 형식이다. 그리고 데이터를 보내는 사람은 누구에게 보내는게 정해지지 않고 일단 그냥 보낸다. 

Kafka에서는 

* 모든 메세지들은 topic을 정해서 만들어진다. 그럼 같은 topic안에 있는 애들끼리 당연히 묶이겠지. 
* 메세지를 받고 보내는 일은 중간에서 kafka cluster가 한다. 클러스터안에는 여러 broker 서버들이 있다. 같은 토픽이 여러 broker에 쪼개져서 저장된다. 
* 하나의 토픽안에 메세지들은 partition으로 나눠져있어서 consumer가 데이터를 받을때 partition을 하나 받는다. 
* 메세지는 id가 있는게 아니라 page offset을 이용해서 indexing을 하는데, consumer가 특정 offset 부터 읽어야한다는 것을 따로 관리한다. 따라서 그 consumer에게 지정된 offset보다 적은 곳에 위치한 데이터들은 이미 수령했다고 칠 수 있다. 
* consumer group이라는 개념을 이용해 여러 consumer들이 하나의 그룹을 이뤄서 데이터를 받는데, 이때 하나의 토픽을 읽는다고 치면, 그 토픽안에 특정 partition은 딱 하나의 consumer만 읽도록 한다.
* 어떤 consumer가 어떤 데이터를 읽고, producer가 보낸 데이터들이 어느 broker에 가고 기타 등등 스케쥴링은 zookeeper라는 lock managing해주는 오픈소스 서비스를 활용한다. 
* 이 load rebalancing  작업이 실제로 병목이 될 수도 있다고 한다. 
*  좀 더 효율적으로 메세지를 전송하기 위해 sendfile API를 사용해 커널 레벨에서 바로 데이터를 전송해서 page cache만 저장하고 중복으로 application 캐시가 생기지 않게 만들었다고 한다. 

<img src="https://e5ce463uma323hyvrr4xumqs-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/Kafka_architecture.png" alt="Apache Kafka And Zookeeper Now Supported On IBM i - IT Jungle" style="zoom:50%;" />

### data class in python 

기존의 파이썬 class와 동일한데 데이터 저장해두기에 좋은 기본적인 함수들을 미리 제공해주는 것이다. 

막 argument넣어주고, init 어쩌고, self 어쩌고 이런걸 줄여준다는 장점. 

프린트하면 안에 무슨 attribute있는지 보여주는 장점. 

```python
from dataclasses import dataclass

@dataclass
class Config:
  node_id: int
  host_addr: str
```

### slots in python

data class와 별개로 slots라는걸 또 발견했는데 실제로 무슨 attribute이 있는지 적어주면 훨씬 retrieval, storage가 효율적이란다. 

원래는 파이썬 클래스도 object니까  `__dict__` 를 통해 attritbute을 관리했는데 이 `__slots__` 를 사용하면 그 dictionary를 저장하는데 드는 메모리와 부르는데 걸리는 시간을 아낄 수 있다고 한다. 

```python
@dataclass
class Config:
	__slots__ = ['node_id', 'host_addr']
  node_id: int
  host_addr: str
```



